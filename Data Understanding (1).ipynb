{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a59755",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "The data used in this project was obtained from the [Zillow housing data](https://www.zillow.com/research/data/). Our aim is to investigate the data in an attempt to get a deeper understanding of it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaae167",
   "metadata": {},
   "source": [
    "#### 2.1 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d06e4",
   "metadata": {},
   "source": [
    "##### Importing the necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496575ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation \n",
    "import pandas as pd\n",
    "# For data analysis\n",
    "import numpy as np\n",
    "#For data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Warning libraries\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c90f08",
   "metadata": {},
   "source": [
    "##### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"zillow_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153677f",
   "metadata": {},
   "source": [
    "##### Displaying First Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66521f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd09ad",
   "metadata": {},
   "source": [
    "##### Displaying last five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4342748",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f2930",
   "metadata": {},
   "source": [
    "The number of columns(272) in the last and first five rows is the same implying consistency in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93110a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of dataset\n",
    "print('Number of rows:',data.shape[0])\n",
    "print('Number of columns:',data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd9cea",
   "metadata": {},
   "source": [
    "The dataset has 14723 rows and 272 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Datatypes\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95554f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the columns\n",
    "columns = {'Columns': ['RegionID','RegionName','City','State','Metro','County Name','Size Rank','Date Columns (265 Columns)'],\n",
    "'Description':['Unique region identifier','Names of the Regions (Zipcodes)','City names for the regions',\n",
    "               'Names of the states','Names of metropolitan areas','Names of counties','Rank of Zipcodes by urbanization',\n",
    "              'Median house prices across the years']}\n",
    "pd.DataFrame(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f1ad9",
   "metadata": {},
   "source": [
    "#### 2.2 Data Quality from the data description\n",
    "* The dataset has 14723 rows and 272 columns. \n",
    "* The columns have both categorical(4) and numerical data(268)\n",
    "* There are many columns because it is in a wide fromat; the last 265 columns describe the dates of the housing data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0fb7f",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2447e7a",
   "metadata": {},
   "source": [
    "Inorder to enhance the efficiency of our model, the data has to be inspected and cleaned to align with our objectives. \n",
    "This is to ensure that we do not generate any misleading information from the analysis. This includes Checking for the validity, consistency, completeness and uniformity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00eb52",
   "metadata": {},
   "source": [
    "#### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e904a01",
   "metadata": {},
   "source": [
    "#### 3.1.1 Completeness\n",
    "\n",
    "*  Checking and Handling for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa75be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values \n",
    "print(f'The data has {data.isna().sum().sum()} missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The following columns contain these missing values {data.isna().sum().sort_values(ascending = False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_missing_vals = (data.isna().sum())*100/len(data)\n",
    "per_missing_vals.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the missing values\n",
    "## Fill the `metro` column with the word \"missing\"\n",
    "data['Metro'].fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48832fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isna().sum().sort_values(ascending=False)\n",
    "percent = missing_values*100/len(data)\n",
    "percent.sort_values(ascending=False)\n",
    "percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling the date columns' missing values\n",
    "data.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd51634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for the missing values again\n",
    "data.isna().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c5597",
   "metadata": {},
   "source": [
    "#### 3.1.2 Validity\n",
    "* Checking for duplicated values \n",
    "* Checking for Outliers in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6282e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicated values  \n",
    "data.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362be2b8",
   "metadata": {},
   "source": [
    "There are no duplicated values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dafdef",
   "metadata": {},
   "source": [
    "We  do not check for outliers in the data, as their presence helps improve the accuracy of the model since in real life there are houses that are priced highly above and below the average. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e5cc6",
   "metadata": {},
   "source": [
    "#### 3.1.3 Uniformity\n",
    "* Checking if the column names are uniform \n",
    "* Exploring the columns more\n",
    "* Checking if the data types are relevant to the column description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking the column names again \n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type of the RegionName column \n",
    "data.dtypes['RegionName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the RegionName column to Zipcode because the column's data is in numerical form\n",
    "data.rename(columns = {'RegionName': \"Zipcode\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of the Zipcode column to categorical  \n",
    "data.Zipcode = data.Zipcode.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the unique values in the Zipcode column\n",
    "data.Zipcode.nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06089cfe",
   "metadata": {},
   "source": [
    "#### Data Construction\n",
    "\n",
    "Here we will  derive new attributes from the data that will be helpful in answering our research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a265da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculating and creating a new column -ROI\n",
    "\n",
    "data['ROI'] = (data['2018-04']/ data['1996-04'])-1\n",
    "\n",
    "\n",
    "\n",
    "#calculating std to be used to find CV\n",
    "data[\"std\"] = data.loc[:, \"1996-04\":\"2018-04\"].std(skipna=True, axis=1)\n",
    "\n",
    "#calculating mean to be used to find CV\n",
    "data[\"mean\"] = data.loc[:, \"1996-04\":\"2018-04\"].mean(skipna=True, axis=1)\n",
    "\n",
    "# calculating and creating a new column - CV\n",
    "\n",
    "data[\"CV\"] = data['std']/data[\"mean\"]\n",
    "\n",
    "# dropping std and mean as they are not necessary for analysis\n",
    "\n",
    "data.drop([\"std\", \"mean\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d00f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9183a",
   "metadata": {},
   "source": [
    "#### Convert data to Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset to convert into long view while preserving df as a wide view for EDA\n",
    "new_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3654dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that changes the dataframe structure from wide view to long view\n",
    "\n",
    "def melt_df(data):\n",
    "    melted = pd.melt(data, id_vars=['RegionID','Zipcode', 'City', 'State', 'Metro', 'CountyName', 'SizeRank','ROI','CV'], var_name='Date')\n",
    "    melted['Date'] = pd.to_datetime(melted['Date'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the melted dataset\n",
    "\n",
    "new_data = melt_df(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab965fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First five rows of the melted dataset\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492bd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottom five rows of the melted dataset\n",
    "\n",
    "new_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns\n",
    "\n",
    "print('Number of rows:',new_data.shape[0])\n",
    "print('Number of columns:',new_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Columns\n",
    "print(f\"Numerical Columns: {new_data.select_dtypes(include='int').columns}\\n\")\n",
    "\n",
    "# Categorical Columns\n",
    "print(f\"Categorical Columns: {new_data.select_dtypes(include='object').columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "new_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0a524",
   "metadata": {},
   "source": [
    "##### Data Indexing \n",
    "While working with time series data in Python, having dates (or datetimes) in the index can be very helpful, especially if they are of DatetimeIndex type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the date column into the index\n",
    "\n",
    "new_data.set_index('Date',inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to confirm if the index column of our new dataframe is Date column \n",
    "if isinstance(new_data.index, pd.DatetimeIndex):\n",
    "    new_data.index.name == 'Date'\n",
    "    print(\"Index column is date!\")\n",
    "else:\n",
    "    print('Index column is not Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting Index column \n",
    "new_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93212778",
   "metadata": {},
   "source": [
    "The output above shows that our dataset clearly fulfills the indexing requirements. Look at the last line:\n",
    "\n",
    "dtype='datetime64[ns]',... length=3901595,...'\n",
    "\n",
    "dtype=datetime[ns] field confirms that the index is made of timestamp objects.\n",
    "length=3901595 shows the total number of entries in our time series data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3552b5",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis\n",
    "\n",
    " Exploration will be done on the data to determine:\n",
    "\n",
    "- Does Urbanization Affect Median House Prices?\n",
    "\n",
    "- Which cities fetch the highest median house prices?\n",
    "\n",
    "- What top 5 Zipcodes have the highest ROI?\n",
    "\n",
    "- Which zipcodes have high price volatility?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f049a",
   "metadata": {},
   "source": [
    "#### Time Series EDA\n",
    "\n",
    "This analysis will answer the question: What is the trend of median houseprices over the years?\n",
    " \n",
    "However, given the large volume of our data, we perform our EDA in two phases: one between 1996 to 2007 and another between 2007 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the data\n",
    "\n",
    "time_series1 = new_data['1996-04-01':'2007-12-31']\n",
    "time_series2 = new_data['2007-01-01':'2018-04-01']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233f530",
   "metadata": {},
   "source": [
    "#### Series 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aba418",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series1_monthly = time_series1.resample('MS').mean()['value']\n",
    "# Draw a line plot using the new data\n",
    "time_series1_monthly.plot(figsize = (22,8))\n",
    "\n",
    "plt.title('Typical Home Value by Month Between 1996 and 2007',fontsize = 20)\n",
    "plt.ylabel('Value in US Dollars ($)',fontsize = 20)\n",
    "plt.xlabel ('1996 - 2007',fontsize = 20)\n",
    "\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks (fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual \n",
    "yearly_data =  time_series1['value'].resample(rule='A').mean()\n",
    "yearly_data.plot.line(color='magenta',)\n",
    "\n",
    "plt.title('Home Value by Year')\n",
    "plt.ylabel('Value in US Dollars ($)')\n",
    "plt.xlabel ('1996 - 2007')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the dataset\n",
    "time_series1_monthly.hist(figsize = (12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ba4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a density plot for temperature dataset\n",
    "time_series1_monthly.plot(kind='kde', figsize = (12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cd430",
   "metadata": {},
   "source": [
    "#### Series 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series2_monthly = time_series2.resample('MS').mean()['value']\n",
    "# Draw a line plot using the new data\n",
    "time_series2_monthly.plot(figsize = (22,8))\n",
    "\n",
    "plt.title('Typical Home Value by Month Between 2007 and April 2018',fontsize = 20)\n",
    "plt.ylabel('Value in US Dollars ($)',fontsize = 20)\n",
    "plt.xlabel ('2007 -2018',fontsize = 20)\n",
    "\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks (fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual \n",
    "yearly_data =  time_series2['value'].resample(rule='A').mean()\n",
    "yearly_data.plot.line(color='magenta',)\n",
    "\n",
    "plt.title('Home Value by Year')\n",
    "plt.ylabel('Value in US Dollars ($)')\n",
    "plt.xlabel ('2007 - 2018')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296acbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the dataset\n",
    "time_series2_monthly.hist(figsize = (12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a density plot for the dataset\n",
    "time_series2_monthly.plot(kind='kde', figsize = (12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e9ced",
   "metadata": {},
   "source": [
    "#### Heatmap for both Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b729ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the yearly group DataFrame\n",
    "year_matrix = new_data['value'].resample(rule='A').mean().to_frame().T\n",
    "\n",
    "# Draw a heatmap with matshow()\n",
    "plt.matshow( year_matrix, interpolation=None, aspect='auto', cmap=plt.cm.Spectral_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d01d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
